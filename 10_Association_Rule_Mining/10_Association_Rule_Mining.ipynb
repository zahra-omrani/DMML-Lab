{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b65ae400",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- The weather-nominal dataset\n",
    "- 1. Generating frequent patterns\n",
    "    - The apriori algorithm\n",
    "    - The FPgrowth algorithm\n",
    "- 2. Association rules generation and evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e69a6e4",
   "metadata": {},
   "source": [
    "# The weather-nominal dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd2cf0",
   "metadata": {},
   "source": [
    "Load the weather-nominal dataset: it is an extremely simple dataset with 13 entries and 5 attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a358f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/weather-nominal.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30589ced",
   "metadata": {},
   "source": [
    "Association Rule Mining can be considered as a two-step process:\n",
    "1. **find all frequent itemsets**: impose a predefined *minimum support* (min sup.).\n",
    "2. **generate *strong* association rules from the freqent itemsets**: typically, association rules are considered interesting if they satisfy both a *minimum support* threshold and a *minimum confidence* threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d30176d",
   "metadata": {},
   "source": [
    "# 1. Generating frequent patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11afa94d",
   "metadata": {},
   "source": [
    "Frequent pattern analysis is beyond the scope of the `scikit-learn` library. In this notebook we will resort to `mlxtend` ([machine learning extension](http://rasbt.github.io/mlxtend/)), one of the third party libraries that implement the most popular frequent pattern mining algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c03cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3332dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns:\n",
    "    data[column]=data[column].apply(lambda x: f'{column}_{x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae589e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5125ffdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c360ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429db16b",
   "metadata": {},
   "source": [
    "### The apriori algorithm\n",
    "\n",
    "Apriori is a popular algorithm for extracting frequent itemsets with applications in association rule learning. The apriori algorithm has been designed to operate on databases containing transactions, such as purchases by customers of a store. \n",
    "\n",
    "An itemset is considered as \"frequent\" if it meets a user-specified support threshold. For instance, if the support threshold is set to 0.5 (50%), a frequent itemset is defined as a set of items that occur together in at least 50% of all transactions in the database.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff4442e",
   "metadata": {},
   "source": [
    "**Encoded format**\n",
    "\n",
    "The allowed values for a DataFrame provided as input at mlxtend's frequent pattern mining algorithms are either 0/1 or True/False (i.e., boolean vector). \n",
    "\n",
    "This encoding complies with the scenario of *market basket analysis*, in which we think of the universe as the set of items available at the store, and each item as a Boolean variable representing the presence or absence of that item. Each basket can be represented by a Boolean vector of values assigned to these variables.\n",
    "\n",
    "The TransactionEncoder converts item lists into transaction data for frequent itemset mining (simply transforms the input dataset into a one-hot encoded NumPy boolean array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cfe4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder \n",
    "te = TransactionEncoder()\n",
    "te_data = te.fit(data.values).transform(data.values)\n",
    "df = pd.DataFrame(te_data, columns=te.columns_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8dc551",
   "metadata": {},
   "source": [
    "Notice that the same encoding can be obtained with `sklearn.preprocessing.OneHotEncoder` and `pandas.get_dummies()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33390ee",
   "metadata": {},
   "source": [
    "Now, obtain the items and itemsets with at least MinSup support (e.g., MinSup = 0.2):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e885ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2fd7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "apriori?\n",
    "# - requires setting of min_support\n",
    "# - requires one-hot encoded dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323adbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_itemset = apriori(df, min_support=0.2, use_colnames=True,verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be032d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9dba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(freq_itemset.support.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df913777",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(f'{x}/14={x/14}') for x in range(3,10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4199bd8",
   "metadata": {},
   "source": [
    "The type of the itemset value is `frozenset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e27a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_itemset.itemsets.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308e0c4a",
   "metadata": {},
   "source": [
    "Differently from the classical python `set`, the `frozenset` type is immutable and hashable â€” its contents cannot be altered after it is created; it can therefore be used as a dictionary key or as an element of another set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e99467",
   "metadata": {},
   "source": [
    "We can leverage the power of pandas to conveniently analyse/filter the results. For instance, we can create the DataFrame of frequent itemsets via apriori and then add a new column that stores the length of each itemset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aa5208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq_itemset['length'] = freq_itemset['itemsets'].apply(lambda x: len(x))\n",
    "freq_itemset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c182840",
   "metadata": {},
   "source": [
    "Filter the results based on some desired criteria (e.g., selects only the *k*-itemset with *k*>2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c8b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_itemset[(freq_itemset['length']>2)&(freq_itemset['support']>= 0.25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d59185b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq_itemset[freq_itemset['itemsets'].apply(lambda x: 'play_yes' in x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f60a5ef",
   "metadata": {},
   "source": [
    "Note: as we are dealing with frozensets, the order does not matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10324fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_itemset[freq_itemset['itemsets']=={\"play_yes\", \"outlook_overcast\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1799604",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_itemset[freq_itemset['itemsets']=={\"outlook_overcast\",\"play_yes\"}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0949db6",
   "metadata": {},
   "source": [
    "### The FPGrowth algorithm\n",
    "\n",
    "FP-Growth is another algorithm for extracting frequent itemsets with applications in association rule learning. It emerged as an efficient alternative to the Apriori algorighm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b250b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import fpgrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f5a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpgrowth?\n",
    "# - again, requires setting of only one parameter: min_support\n",
    "# - requires one-hot encoded dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53764feb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fpgrowth(df, min_support=0.2,use_colnames=True,verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73267366",
   "metadata": {},
   "source": [
    "Note that, given a fixed minsup, the set of frequent patterns mined by *Apriori* and *FP-Growth* is **exactly the same**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1ef564",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 100 -r 10 apriori(df, min_support=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03798afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 100 -r 10 fpgrowth(df, min_support=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06037a70",
   "metadata": {},
   "source": [
    "The dataset is extremely small and the difference is limited.\n",
    "Anyway, fpgrowth takes typically less time, since it requires just two scans of the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fdc7b7",
   "metadata": {},
   "source": [
    "## 2. Association rules generation and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fde65ce",
   "metadata": {},
   "source": [
    "An association rule is an implication expression of the form $X \\rightarrow Y$, where $X$ and $Y$ are disjoint itemsets.\n",
    "\n",
    "Association rules can be generated as follows:\n",
    "- for each frequent itemset $l$, generate all nonempty subset of $l$\n",
    "- for every nonempty subset $s$ of $l$, output the rule \"$s \\rightarrow (l-s)$\" if $\\frac{\\text{support}(l)}{\\text{support}(s)}>\\text{min_conf}$\n",
    "\n",
    "As the rules are generated from frequent itemsets, each one automatically satisfy the *minimum support*.\n",
    "\n",
    "In the following we generate association rules from the frequent itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19e0ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251fd16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "association_rules?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf94c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "association_rules(freq_itemset, metric=\"confidence\", min_threshold=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ebbf43",
   "metadata": {},
   "source": [
    "Let $A \\rightarrow C$ be a rule ($A$ and $C$ stands for the antecedent and the consequents, respectively).\n",
    "\n",
    "The table produced by the association rule mining algorithm contains three different support metrics:\n",
    "- **antecedent support**: proportion of transactions that contain the antecedent $A$  \n",
    "\n",
    "$\\quad \\text{support}(A) \\quad \\text{range:}\\; [0,1]$\n",
    "- **consequent support**:  proportion of transactions that contain the consequent $C$ \n",
    "\n",
    "$\\quad \\text{support}(C) \\quad \\text{range:}\\; [0,1]$\n",
    "- **support**: computes the support of the combined itemset $A \\cup C$  \n",
    "\n",
    "$\\quad \\text{support}(A\\rightarrow C)=\\text{support}(A \\cup C) \\quad \\text{range:}\\; [0,1]$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7960010",
   "metadata": {},
   "source": [
    "Many association rule mining algorithms employ the *support-confidence* framework. Indeed, we find also confidence among the metrics:\n",
    "\n",
    "- **confidence**: probability of seeing the consequent in a transaction given that it also contains the antecedent. \n",
    "\n",
    "$\\quad \\text{confidence}(A \\rightarrow C)  = \\frac{\\text{support}(A \\rightarrow C)}{\\text{support}(A)} \\quad \\text{range:}\\; [0,1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f5dab9",
   "metadata": {},
   "source": [
    "The *support-confidence* framework, however, may still lead to rules that are uninteresting to the users.\n",
    "Different metrics have been developed to supplement such a framework for the evaluation of an association rule. The current implementation of `mlxtend` makes use of confidence, lift, leverage and conviction metrics, thus enabling a *support-confidence-correlation* framework.\n",
    "\n",
    "\n",
    "- **lift**: how many times more often $A$ and $C$ occur together than expected if they were statistically independent \n",
    "\n",
    "$\\quad \\text{lift}(A \\rightarrow C) = \\text{lift}(C \\rightarrow A) = \\frac{\\text{confidence}(A \\rightarrow C)}{\\text{support}(C)} = \\frac{\\text{confidence}(C \\rightarrow A)}{\\text{support}(A)}\\quad \\text{range:}\\; [0,\\infty]$\n",
    "\n",
    "- **leverage**: difference between the observed frequency of A and C appearing together and the frequency that would be expected if A and C were independent. A leverage value of 0 indicates independence.\n",
    "\n",
    "$\\quad \\text{leverage}(A \\rightarrow C) = \\text{support}(A \\rightarrow C) - \\text{support}(A) \\times \\text{support}(C) \\quad \\text{range:}\\; [-1,1]$\n",
    "\n",
    "- **conviction**: high conviction value means that the consequent is highly depending on the antecedent. Similar to lift, if items are independent, the conviction is 1.\n",
    "\n",
    "$\\quad \\text{conviction}(A \\rightarrow C) = \\frac{1-\\text{support}(C)}{1-\\text{confidence}(A \\rightarrow C)}  \\quad \\text{range:}\\; [0,\\infty]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9ac7e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "association_rules(freq_itemset, metric=\"lift\", min_threshold=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ece501",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = association_rules(freq_itemset, metric=\"lift\", min_threshold=1.1)\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88b01e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rules[\"antecedent_len\"] = rules[\"antecedents\"].apply(lambda x: len(x))\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb6bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules[ (rules['antecedent_len'] >= 2) &\n",
    "       (rules['confidence'] > 0.75) &\n",
    "       (rules['lift'] > 1.2) ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
